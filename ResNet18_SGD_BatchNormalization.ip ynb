{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet18_SGD_BatchNormalization.ip ynb","provenance":[{"file_id":"1cx5AuJaSiyG0owbePsXG5PXXtXqRz-U6","timestamp":1601613787180},{"file_id":"1x_ZpnMiObaiwzzDORgE6UOgYksjWcADD","timestamp":1601527162849},{"file_id":"1FCLEl__6MV052BUgh8Z_HkWIC83pRxw7","timestamp":1601523678178},{"file_id":"1eOqwwHBbBqR-lvMO8pAekz5bomeGu3Yp","timestamp":1601518408894}],"machine_shape":"hm","authorship_tag":"ABX9TyMhRaBGJ4+3IX0h3k/CeAK4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"crBSvOsTig9y","executionInfo":{"status":"ok","timestamp":1602539456293,"user_tz":240,"elapsed":2093,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["import tensorflow as tf"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"IPl3uGq8iit8","executionInfo":{"status":"ok","timestamp":1602539456294,"user_tz":240,"elapsed":2090,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["import keras"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxS_tTGxilSV","executionInfo":{"status":"ok","timestamp":1602539456294,"user_tz":240,"elapsed":2088,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["from keras.datasets import cifar100"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXkUXpGiinV5","executionInfo":{"status":"ok","timestamp":1602539456295,"user_tz":240,"elapsed":2087,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["from keras.utils import to_categorical"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcbBCZrulERy","executionInfo":{"status":"ok","timestamp":1602539464591,"user_tz":240,"elapsed":10375,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}},"outputId":"96005fde-c06a-4fa9-c74f-bb3f0f1ab8b8","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["(train_X, train_Y_),(test_X, test_Y_) = cifar100.load_data()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169009152/169001437 [==============================] - 6s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0I3851G9qYkd","executionInfo":{"status":"ok","timestamp":1602539464592,"user_tz":240,"elapsed":10374,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["train_Y = to_categorical(train_Y_)\n","test_Y = to_categorical(test_Y_)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTfxu644qgmL","executionInfo":{"status":"ok","timestamp":1602539464870,"user_tz":240,"elapsed":10650,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["train_X = train_X.astype('float32')/255\n","test_X = test_X.astype('float32')/255"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ekLBl8g2tnv","executionInfo":{"status":"ok","timestamp":1602539464871,"user_tz":240,"elapsed":10649,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["from keras.models import Model"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACeUUfBf3W7-","executionInfo":{"status":"ok","timestamp":1602539464871,"user_tz":240,"elapsed":10648,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["from keras.layers import  Conv2D, Dense, BatchNormalization, Flatten, MaxPool2D, Input, Dropout, AveragePooling2D,Add"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"HizujF9JcxGR","executionInfo":{"status":"ok","timestamp":1602539464872,"user_tz":240,"elapsed":10647,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"-d1su4713Zi3","executionInfo":{"status":"ok","timestamp":1602539464872,"user_tz":240,"elapsed":10646,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["def create_ResNet18_Network():\n","  input_layer = Input(shape = (32,32,3))\n","  conv_layer1 = Conv2D(filters = 32, kernel_size = (7,7) , strides = (2,2), padding = 'same', activation = 'relu')(input_layer)\n","  pool_layer1 = MaxPool2D(pool_size=(2,2), strides = (2,2))(conv_layer1)\n","  conv_layer2a = Conv2D(filters = 32, kernel_size=(3,3), padding = 'same', activation = 'relu')(pool_layer1)\n","  conv_layer2b = Conv2D(filters = 32, kernel_size=(3,3), padding = 'same', activation = 'relu')(conv_layer2a)\n","  add_layer1 = Add()([conv_layer2a, conv_layer2b])\n","  conv_layer2c = Conv2D(filters = 32, kernel_size=(3,3), padding = 'same', activation = 'relu')(add_layer1)\n","  conv_layer2d = Conv2D(filters = 32, kernel_size=(3,3), padding = 'same', activation = 'relu')(conv_layer2c)\n","  add_layer2 = Add()([conv_layer2c, conv_layer2d])\n","  conv_layer3a = Conv2D(filters = 64, kernel_size=(3,3), padding = 'same', activation = 'relu')(add_layer2)\n","  conv_layer3b = Conv2D(filters = 64, kernel_size=(3,3), padding = 'same', activation = 'relu')(conv_layer2c)\n","  add_layer3 =  Add()([conv_layer3a, conv_layer3b])\n","  batch_norm3 = BatchNormalization()(add_layer3)\n","  conv_layer3c = Conv2D(filters = 64, kernel_size=(3,3), padding = 'same', activation = 'relu')(batch_norm3)\n","  conv_layer3d = Conv2D(filters = 64, kernel_size=(3,3), padding = 'same', activation = 'relu')(conv_layer3c)\n","  add_layer4 = Add()([conv_layer3c, conv_layer3d])\n","  #conv_layer4a = Conv2D(filters = 32, kernel_size=(3,3), padding = 'same', activation = 'relu')(add_layer4)\n","  #conv_layer4b = Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu')(conv_layer4a)\n","  #add_layer5 = Add()([conv_layer4a, conv_layer4b])\n","  #conv_layer4c = Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu')(add_layer5)\n","  #conv_layer4d = Conv2D(filters = 32, kernel_size=(3,3), padding = 'same', activation = 'relu')(conv_layer4c)\n","  #add_layer6 = Add()([conv_layer4c, conv_layer4d])\n","  pool_layer4 = AveragePooling2D(pool_size = (2,2),strides=(1,1))(add_layer4)\n","  batch_norm4 = BatchNormalization()(pool_layer4)\n","  flatten = Flatten()(batch_norm4)\n","  dense1 = Dense(100, activation = 'softmax')(flatten)\n","  model = Model(inputs = input_layer, outputs = dense1)\n","  return model"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNHFDkEA3bPv","executionInfo":{"status":"ok","timestamp":1602539471551,"user_tz":240,"elapsed":17322,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["model  = create_ResNet18_Network()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ct3fNyrBdL7f","executionInfo":{"status":"ok","timestamp":1602539471552,"user_tz":240,"elapsed":17322,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["model.compile(optimizer='sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"yf4DV0rrdj6z","executionInfo":{"status":"ok","timestamp":1602539471552,"user_tz":240,"elapsed":17316,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}},"outputId":"62db9d53-ff0d-4ca8-c9f2-535e00baabc6","colab":{"base_uri":"https://localhost:8080/","height":890}},"source":["model.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 16, 16, 32)   4736        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 8, 8, 32)     0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 8, 8, 32)     9248        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 8, 8, 32)     9248        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 8, 8, 32)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 8, 8, 32)     9248        add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 8, 8, 32)     9248        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 8, 8, 32)     0           conv2d_3[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 8, 8, 64)     18496       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 8, 8, 64)     18496       conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 8, 8, 64)     0           conv2d_5[0][0]                   \n","                                                                 conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 8, 8, 64)     256         add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 8, 8, 64)     36928       conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 8, 8, 64)     0           conv2d_7[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 7, 7, 64)     0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 7, 7, 64)     256         average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 3136)         0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 100)          313700      flatten[0][0]                    \n","==================================================================================================\n","Total params: 466,788\n","Trainable params: 466,532\n","Non-trainable params: 256\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zOwTkQHTpwy_","executionInfo":{"status":"ok","timestamp":1602539471553,"user_tz":240,"elapsed":17315,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["from google.colab import drive"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"NI9XnsTHpxDf","executionInfo":{"status":"ok","timestamp":1602539504649,"user_tz":240,"elapsed":50404,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}},"outputId":"01bbb6f7-e5e1-4003-802c-1d85268c3ac9","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["drive.mount('/content/gdrive/')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AsxAqkfopxG9","executionInfo":{"status":"ok","timestamp":1602539504652,"user_tz":240,"elapsed":50405,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["path = F'/content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5'"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTmsNls13ddl","executionInfo":{"status":"ok","timestamp":1602539504653,"user_tz":240,"elapsed":50405,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["earlyStopping = EarlyStopping(monitor = 'val_accuracy', patience = 50)\n","checkpoint = ModelCheckpoint(filepath = path, monitor = 'val_accuracy',verbose = 2,  save_best_only=True, save_weights_only=True, mode = 'max')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmFpc4s-3fb8","executionInfo":{"status":"ok","timestamp":1602540730109,"user_tz":240,"elapsed":1275855,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}},"outputId":"09435c1b-b05c-4db6-c024-427344c61013","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = model.fit(x = train_X, y = train_Y, batch_size = 32, epochs = 200, validation_split=0.1, callbacks=[checkpoint])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","1407/1407 [==============================] - ETA: 0s - loss: 3.9299 - accuracy: 0.1153\n","Epoch 00001: val_accuracy improved from -inf to 0.10280, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 7s 5ms/step - loss: 3.9299 - accuracy: 0.1153 - val_loss: 4.2542 - val_accuracy: 0.1028\n","Epoch 2/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 3.2790 - accuracy: 0.2173\n","Epoch 00002: val_accuracy improved from 0.10280 to 0.18400, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 7s 5ms/step - loss: 3.2778 - accuracy: 0.2176 - val_loss: 3.5375 - val_accuracy: 0.1840\n","Epoch 3/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 2.9502 - accuracy: 0.2779\n","Epoch 00003: val_accuracy improved from 0.18400 to 0.18540, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 7s 5ms/step - loss: 2.9496 - accuracy: 0.2781 - val_loss: 3.8088 - val_accuracy: 0.1854\n","Epoch 4/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 2.7096 - accuracy: 0.3262\n","Epoch 00004: val_accuracy improved from 0.18540 to 0.26840, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 6s 4ms/step - loss: 2.7095 - accuracy: 0.3261 - val_loss: 3.1152 - val_accuracy: 0.2684\n","Epoch 5/200\n","1407/1407 [==============================] - ETA: 0s - loss: 2.5127 - accuracy: 0.3637\n","Epoch 00005: val_accuracy did not improve from 0.26840\n","1407/1407 [==============================] - 6s 4ms/step - loss: 2.5127 - accuracy: 0.3637 - val_loss: 3.3162 - val_accuracy: 0.2290\n","Epoch 6/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 2.3577 - accuracy: 0.3988\n","Epoch 00006: val_accuracy improved from 0.26840 to 0.30600, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 7s 5ms/step - loss: 2.3584 - accuracy: 0.3987 - val_loss: 2.8762 - val_accuracy: 0.3060\n","Epoch 7/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 2.2127 - accuracy: 0.4313\n","Epoch 00007: val_accuracy did not improve from 0.30600\n","1407/1407 [==============================] - 6s 4ms/step - loss: 2.2129 - accuracy: 0.4313 - val_loss: 3.0364 - val_accuracy: 0.2872\n","Epoch 8/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 2.0850 - accuracy: 0.4578\n","Epoch 00008: val_accuracy improved from 0.30600 to 0.31920, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 7s 5ms/step - loss: 2.0854 - accuracy: 0.4576 - val_loss: 2.8953 - val_accuracy: 0.3192\n","Epoch 9/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 1.9658 - accuracy: 0.4881\n","Epoch 00009: val_accuracy improved from 0.31920 to 0.34780, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 7s 5ms/step - loss: 1.9670 - accuracy: 0.4878 - val_loss: 2.7825 - val_accuracy: 0.3478\n","Epoch 10/200\n","1395/1407 [============================>.] - ETA: 0s - loss: 1.8604 - accuracy: 0.5091\n","Epoch 00010: val_accuracy did not improve from 0.34780\n","1407/1407 [==============================] - 6s 4ms/step - loss: 1.8603 - accuracy: 0.5093 - val_loss: 3.0049 - val_accuracy: 0.3208\n","Epoch 11/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 1.7466 - accuracy: 0.5357\n","Epoch 00011: val_accuracy did not improve from 0.34780\n","1407/1407 [==============================] - 6s 4ms/step - loss: 1.7469 - accuracy: 0.5356 - val_loss: 3.5810 - val_accuracy: 0.2650\n","Epoch 12/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 1.6464 - accuracy: 0.5587\n","Epoch 00012: val_accuracy did not improve from 0.34780\n","1407/1407 [==============================] - 6s 4ms/step - loss: 1.6474 - accuracy: 0.5586 - val_loss: 4.3102 - val_accuracy: 0.2104\n","Epoch 13/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.5435 - accuracy: 0.5851\n","Epoch 00013: val_accuracy did not improve from 0.34780\n","1407/1407 [==============================] - 6s 4ms/step - loss: 1.5435 - accuracy: 0.5851 - val_loss: 3.5759 - val_accuracy: 0.2858\n","Epoch 14/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 1.4487 - accuracy: 0.6061\n","Epoch 00014: val_accuracy did not improve from 0.34780\n","1407/1407 [==============================] - 6s 4ms/step - loss: 1.4482 - accuracy: 0.6061 - val_loss: 4.1017 - val_accuracy: 0.2318\n","Epoch 15/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 1.3500 - accuracy: 0.6313\n","Epoch 00015: val_accuracy did not improve from 0.34780\n","1407/1407 [==============================] - 6s 4ms/step - loss: 1.3506 - accuracy: 0.6309 - val_loss: 3.1753 - val_accuracy: 0.3362\n","Epoch 16/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.2550 - accuracy: 0.6533\n","Epoch 00016: val_accuracy did not improve from 0.34780\n","1407/1407 [==============================] - 6s 4ms/step - loss: 1.2550 - accuracy: 0.6533 - val_loss: 3.1856 - val_accuracy: 0.3468\n","Epoch 17/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.1701 - accuracy: 0.6741\n","Epoch 00017: val_accuracy did not improve from 0.34780\n","1407/1407 [==============================] - 6s 4ms/step - loss: 1.1700 - accuracy: 0.6741 - val_loss: 3.2321 - val_accuracy: 0.3468\n","Epoch 18/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 1.0743 - accuracy: 0.6998\n","Epoch 00018: val_accuracy improved from 0.34780 to 0.35480, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 7s 5ms/step - loss: 1.0753 - accuracy: 0.6995 - val_loss: 3.2698 - val_accuracy: 0.3548\n","Epoch 19/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.9894 - accuracy: 0.7181\n","Epoch 00019: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.9896 - accuracy: 0.7180 - val_loss: 3.3788 - val_accuracy: 0.3272\n","Epoch 20/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.9164 - accuracy: 0.7357\n","Epoch 00020: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.9165 - accuracy: 0.7357 - val_loss: 4.0579 - val_accuracy: 0.2878\n","Epoch 21/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.8299 - accuracy: 0.7590\n","Epoch 00021: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.8301 - accuracy: 0.7589 - val_loss: 3.5579 - val_accuracy: 0.3282\n","Epoch 22/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.7479 - accuracy: 0.7838\n","Epoch 00022: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.7485 - accuracy: 0.7836 - val_loss: 4.0640 - val_accuracy: 0.3042\n","Epoch 23/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.6766 - accuracy: 0.8021\n","Epoch 00023: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.6777 - accuracy: 0.8019 - val_loss: 4.1853 - val_accuracy: 0.3138\n","Epoch 24/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.6068 - accuracy: 0.8224\n","Epoch 00024: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.6069 - accuracy: 0.8224 - val_loss: 4.2297 - val_accuracy: 0.2876\n","Epoch 25/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.5348 - accuracy: 0.8436\n","Epoch 00025: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.5351 - accuracy: 0.8434 - val_loss: 4.2438 - val_accuracy: 0.3268\n","Epoch 26/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.4755 - accuracy: 0.8606\n","Epoch 00026: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.4765 - accuracy: 0.8603 - val_loss: 3.9182 - val_accuracy: 0.3462\n","Epoch 27/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.4063 - accuracy: 0.8838\n","Epoch 00027: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.4074 - accuracy: 0.8833 - val_loss: 4.1631 - val_accuracy: 0.3292\n","Epoch 28/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.3552 - accuracy: 0.8992\n","Epoch 00028: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.3557 - accuracy: 0.8990 - val_loss: 4.4385 - val_accuracy: 0.3248\n","Epoch 29/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.3176 - accuracy: 0.9097\n","Epoch 00029: val_accuracy did not improve from 0.35480\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.3181 - accuracy: 0.9094 - val_loss: 4.2235 - val_accuracy: 0.3528\n","Epoch 30/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.2550 - accuracy: 0.9320\n","Epoch 00030: val_accuracy improved from 0.35480 to 0.36140, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 6s 5ms/step - loss: 0.2550 - accuracy: 0.9320 - val_loss: 4.2690 - val_accuracy: 0.3614\n","Epoch 31/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.9435\n","Epoch 00031: val_accuracy did not improve from 0.36140\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.2128 - accuracy: 0.9433 - val_loss: 4.9806 - val_accuracy: 0.2970\n","Epoch 32/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9545\n","Epoch 00032: val_accuracy did not improve from 0.36140\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.1835 - accuracy: 0.9545 - val_loss: 4.3359 - val_accuracy: 0.3608\n","Epoch 33/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9709\n","Epoch 00033: val_accuracy did not improve from 0.36140\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.1365 - accuracy: 0.9708 - val_loss: 4.7823 - val_accuracy: 0.3330\n","Epoch 34/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9815\n","Epoch 00034: val_accuracy did not improve from 0.36140\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.1041 - accuracy: 0.9814 - val_loss: 4.6936 - val_accuracy: 0.3346\n","Epoch 35/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9883\n","Epoch 00035: val_accuracy improved from 0.36140 to 0.37260, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 6s 5ms/step - loss: 0.0804 - accuracy: 0.9883 - val_loss: 4.4664 - val_accuracy: 0.3726\n","Epoch 36/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9932\n","Epoch 00036: val_accuracy did not improve from 0.37260\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0599 - accuracy: 0.9932 - val_loss: 4.6555 - val_accuracy: 0.3550\n","Epoch 37/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9969\n","Epoch 00037: val_accuracy did not improve from 0.37260\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0437 - accuracy: 0.9969 - val_loss: 4.5476 - val_accuracy: 0.3704\n","Epoch 38/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9984\n","Epoch 00038: val_accuracy improved from 0.37260 to 0.37400, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 6s 5ms/step - loss: 0.0332 - accuracy: 0.9984 - val_loss: 4.6240 - val_accuracy: 0.3740\n","Epoch 39/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9990\n","Epoch 00039: val_accuracy did not improve from 0.37400\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0289 - accuracy: 0.9990 - val_loss: 4.8717 - val_accuracy: 0.3520\n","Epoch 40/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9990\n","Epoch 00040: val_accuracy did not improve from 0.37400\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0242 - accuracy: 0.9990 - val_loss: 4.9879 - val_accuracy: 0.3480\n","Epoch 41/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9992\n","Epoch 00041: val_accuracy did not improve from 0.37400\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0216 - accuracy: 0.9992 - val_loss: 4.7373 - val_accuracy: 0.3654\n","Epoch 42/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9995\n","Epoch 00042: val_accuracy did not improve from 0.37400\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0186 - accuracy: 0.9995 - val_loss: 4.7042 - val_accuracy: 0.3698\n","Epoch 43/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9994\n","Epoch 00043: val_accuracy improved from 0.37400 to 0.37720, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 7s 5ms/step - loss: 0.0178 - accuracy: 0.9994 - val_loss: 4.7524 - val_accuracy: 0.3772\n","Epoch 44/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9995\n","Epoch 00044: val_accuracy did not improve from 0.37720\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0161 - accuracy: 0.9995 - val_loss: 4.8040 - val_accuracy: 0.3718\n","Epoch 45/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9995\n","Epoch 00045: val_accuracy did not improve from 0.37720\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0153 - accuracy: 0.9995 - val_loss: 4.8403 - val_accuracy: 0.3688\n","Epoch 46/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9995\n","Epoch 00046: val_accuracy did not improve from 0.37720\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0151 - accuracy: 0.9995 - val_loss: 4.9155 - val_accuracy: 0.3704\n","Epoch 47/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9995\n","Epoch 00047: val_accuracy improved from 0.37720 to 0.37740, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 6s 5ms/step - loss: 0.0143 - accuracy: 0.9995 - val_loss: 4.8238 - val_accuracy: 0.3774\n","Epoch 48/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9996\n","Epoch 00048: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0127 - accuracy: 0.9996 - val_loss: 5.5891 - val_accuracy: 0.3328\n","Epoch 49/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9994\n","Epoch 00049: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0153 - accuracy: 0.9994 - val_loss: 4.8771 - val_accuracy: 0.3730\n","Epoch 50/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9995\n","Epoch 00050: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0123 - accuracy: 0.9995 - val_loss: 5.0251 - val_accuracy: 0.3616\n","Epoch 51/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9995\n","Epoch 00051: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0127 - accuracy: 0.9994 - val_loss: 5.0906 - val_accuracy: 0.3696\n","Epoch 52/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9995\n","Epoch 00052: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0126 - accuracy: 0.9995 - val_loss: 5.3399 - val_accuracy: 0.3438\n","Epoch 53/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9996\n","Epoch 00053: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0113 - accuracy: 0.9996 - val_loss: 5.0185 - val_accuracy: 0.3700\n","Epoch 54/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9996\n","Epoch 00054: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0106 - accuracy: 0.9996 - val_loss: 4.9708 - val_accuracy: 0.3746\n","Epoch 55/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9996\n","Epoch 00055: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0101 - accuracy: 0.9996 - val_loss: 5.0036 - val_accuracy: 0.3708\n","Epoch 56/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9996\n","Epoch 00056: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0092 - accuracy: 0.9996 - val_loss: 5.0117 - val_accuracy: 0.3726\n","Epoch 57/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9995\n","Epoch 00057: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0102 - accuracy: 0.9995 - val_loss: 5.0102 - val_accuracy: 0.3770\n","Epoch 58/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9996\n","Epoch 00058: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0094 - accuracy: 0.9996 - val_loss: 5.0333 - val_accuracy: 0.3768\n","Epoch 59/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9996\n","Epoch 00059: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 7s 5ms/step - loss: 0.0097 - accuracy: 0.9996 - val_loss: 5.0680 - val_accuracy: 0.3774\n","Epoch 60/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9996\n","Epoch 00060: val_accuracy did not improve from 0.37740\n","1407/1407 [==============================] - 6s 5ms/step - loss: 0.0092 - accuracy: 0.9996 - val_loss: 5.1371 - val_accuracy: 0.3708\n","Epoch 61/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9995\n","Epoch 00061: val_accuracy improved from 0.37740 to 0.37860, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 6s 5ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 5.1031 - val_accuracy: 0.3786\n","Epoch 62/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9996\n","Epoch 00062: val_accuracy did not improve from 0.37860\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0090 - accuracy: 0.9996 - val_loss: 5.1145 - val_accuracy: 0.3772\n","Epoch 63/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9996\n","Epoch 00063: val_accuracy did not improve from 0.37860\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 5.2140 - val_accuracy: 0.3698\n","Epoch 64/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9995\n","Epoch 00064: val_accuracy did not improve from 0.37860\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 5.1138 - val_accuracy: 0.3744\n","Epoch 65/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9996\n","Epoch 00065: val_accuracy did not improve from 0.37860\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 5.1959 - val_accuracy: 0.3756\n","Epoch 66/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9996\n","Epoch 00066: val_accuracy did not improve from 0.37860\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 5.1756 - val_accuracy: 0.3724\n","Epoch 67/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9996\n","Epoch 00067: val_accuracy did not improve from 0.37860\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0075 - accuracy: 0.9996 - val_loss: 5.1786 - val_accuracy: 0.3754\n","Epoch 68/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9997\n","Epoch 00068: val_accuracy improved from 0.37860 to 0.37880, saving model to /content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5\n","1407/1407 [==============================] - 6s 5ms/step - loss: 0.0074 - accuracy: 0.9997 - val_loss: 5.1818 - val_accuracy: 0.3788\n","Epoch 69/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9997\n","Epoch 00069: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 5.1909 - val_accuracy: 0.3738\n","Epoch 70/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9997\n","Epoch 00070: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 5.2239 - val_accuracy: 0.3758\n","Epoch 71/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9997\n","Epoch 00071: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 5.2047 - val_accuracy: 0.3754\n","Epoch 72/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9997\n","Epoch 00072: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 5.2196 - val_accuracy: 0.3738\n","Epoch 73/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9997\n","Epoch 00073: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 5.2208 - val_accuracy: 0.3752\n","Epoch 74/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9997\n","Epoch 00074: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 5.2713 - val_accuracy: 0.3764\n","Epoch 75/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9997\n","Epoch 00075: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 5.3038 - val_accuracy: 0.3768\n","Epoch 76/200\n","1395/1407 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9996\n","Epoch 00076: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 5.2643 - val_accuracy: 0.3750\n","Epoch 77/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9996\n","Epoch 00077: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 5.4047 - val_accuracy: 0.3694\n","Epoch 78/200\n","1395/1407 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9996\n","Epoch 00078: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0077 - accuracy: 0.9996 - val_loss: 5.2576 - val_accuracy: 0.3760\n","Epoch 79/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9996\n","Epoch 00079: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 5.3075 - val_accuracy: 0.3700\n","Epoch 80/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9997\n","Epoch 00080: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 5.3289 - val_accuracy: 0.3726\n","Epoch 81/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9997\n","Epoch 00081: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 5.3234 - val_accuracy: 0.3758\n","Epoch 82/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9996\n","Epoch 00082: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0071 - accuracy: 0.9996 - val_loss: 5.3539 - val_accuracy: 0.3682\n","Epoch 83/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9996\n","Epoch 00083: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 5.4274 - val_accuracy: 0.3696\n","Epoch 84/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9997\n","Epoch 00084: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 5.3305 - val_accuracy: 0.3754\n","Epoch 85/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9997\n","Epoch 00085: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 5.3565 - val_accuracy: 0.3770\n","Epoch 86/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9996\n","Epoch 00086: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 5.3800 - val_accuracy: 0.3720\n","Epoch 87/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9996\n","Epoch 00087: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 5.3696 - val_accuracy: 0.3724\n","Epoch 88/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9996\n","Epoch 00088: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 5.3788 - val_accuracy: 0.3736\n","Epoch 89/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9995\n","Epoch 00089: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 5.3950 - val_accuracy: 0.3730\n","Epoch 90/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9996\n","Epoch 00090: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 5.4340 - val_accuracy: 0.3760\n","Epoch 91/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9996\n","Epoch 00091: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 5.4108 - val_accuracy: 0.3756\n","Epoch 92/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9996\n","Epoch 00092: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 5.4558 - val_accuracy: 0.3738\n","Epoch 93/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9996\n","Epoch 00093: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 5.4245 - val_accuracy: 0.3746\n","Epoch 94/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9996\n","Epoch 00094: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 5.4275 - val_accuracy: 0.3788\n","Epoch 95/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9997\n","Epoch 00095: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 5.4424 - val_accuracy: 0.3732\n","Epoch 96/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9998\n","Epoch 00096: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 5.4626 - val_accuracy: 0.3756\n","Epoch 97/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9997\n","Epoch 00097: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 5.4730 - val_accuracy: 0.3726\n","Epoch 98/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9996\n","Epoch 00098: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 5.8658 - val_accuracy: 0.3540\n","Epoch 99/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9997\n","Epoch 00099: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 5.4756 - val_accuracy: 0.3744\n","Epoch 100/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9997\n","Epoch 00100: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 5.4713 - val_accuracy: 0.3770\n","Epoch 101/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9996\n","Epoch 00101: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 5.5139 - val_accuracy: 0.3758\n","Epoch 102/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9998\n","Epoch 00102: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 5.5300 - val_accuracy: 0.3692\n","Epoch 103/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9996\n","Epoch 00103: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0052 - accuracy: 0.9996 - val_loss: 5.5123 - val_accuracy: 0.3724\n","Epoch 104/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9997\n","Epoch 00104: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 5.5252 - val_accuracy: 0.3738\n","Epoch 105/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9997\n","Epoch 00105: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 5.5244 - val_accuracy: 0.3756\n","Epoch 106/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9997\n","Epoch 00106: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 5.5537 - val_accuracy: 0.3744\n","Epoch 107/200\n","1394/1407 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9996\n","Epoch 00107: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 5.6524 - val_accuracy: 0.3674\n","Epoch 108/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9997\n","Epoch 00108: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 5.5600 - val_accuracy: 0.3722\n","Epoch 109/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9996\n","Epoch 00109: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 6.2066 - val_accuracy: 0.3264\n","Epoch 110/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9996\n","Epoch 00110: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 5ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 5.5716 - val_accuracy: 0.3720\n","Epoch 111/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9996\n","Epoch 00111: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 7s 5ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 5.5777 - val_accuracy: 0.3690\n","Epoch 112/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9996\n","Epoch 00112: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 5.5741 - val_accuracy: 0.3720\n","Epoch 113/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9997\n","Epoch 00113: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 5.6513 - val_accuracy: 0.3726\n","Epoch 114/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9997\n","Epoch 00114: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 5.6183 - val_accuracy: 0.3782\n","Epoch 115/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9997\n","Epoch 00115: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 5.5926 - val_accuracy: 0.3720\n","Epoch 116/200\n","1395/1407 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9997\n","Epoch 00116: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 5.6061 - val_accuracy: 0.3722\n","Epoch 117/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9996\n","Epoch 00117: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 5.6129 - val_accuracy: 0.3724\n","Epoch 118/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9997\n","Epoch 00118: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 5.6111 - val_accuracy: 0.3724\n","Epoch 119/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9997\n","Epoch 00119: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 5.6753 - val_accuracy: 0.3732\n","Epoch 120/200\n","1395/1407 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9997\n","Epoch 00120: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 5.6114 - val_accuracy: 0.3732\n","Epoch 121/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9998\n","Epoch 00121: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 5.6325 - val_accuracy: 0.3734\n","Epoch 122/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9997\n","Epoch 00122: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 5.6236 - val_accuracy: 0.3752\n","Epoch 123/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9997\n","Epoch 00123: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 5.6355 - val_accuracy: 0.3758\n","Epoch 124/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9997\n","Epoch 00124: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 5.6156 - val_accuracy: 0.3724\n","Epoch 125/200\n","1395/1407 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9997\n","Epoch 00125: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 5.6466 - val_accuracy: 0.3730\n","Epoch 126/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9997\n","Epoch 00126: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 6.1482 - val_accuracy: 0.3490\n","Epoch 127/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9997\n","Epoch 00127: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 5.6869 - val_accuracy: 0.3746\n","Epoch 128/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9997\n","Epoch 00128: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 5.6631 - val_accuracy: 0.3740\n","Epoch 129/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9997\n","Epoch 00129: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 5.6549 - val_accuracy: 0.3724\n","Epoch 130/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9997\n","Epoch 00130: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 5.6847 - val_accuracy: 0.3770\n","Epoch 131/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9997\n","Epoch 00131: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 5.6838 - val_accuracy: 0.3726\n","Epoch 132/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998\n","Epoch 00132: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 5.6795 - val_accuracy: 0.3750\n","Epoch 133/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997\n","Epoch 00133: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 5.7452 - val_accuracy: 0.3746\n","Epoch 134/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9997\n","Epoch 00134: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 5.6922 - val_accuracy: 0.3718\n","Epoch 135/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9997\n","Epoch 00135: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 5.7240 - val_accuracy: 0.3738\n","Epoch 136/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9997\n","Epoch 00136: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 5.6993 - val_accuracy: 0.3744\n","Epoch 137/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9997\n","Epoch 00137: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 5.7161 - val_accuracy: 0.3742\n","Epoch 138/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9997\n","Epoch 00138: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 5.7309 - val_accuracy: 0.3734\n","Epoch 139/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9997\n","Epoch 00139: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 5.7609 - val_accuracy: 0.3756\n","Epoch 140/200\n","1395/1407 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997\n","Epoch 00140: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 5.7563 - val_accuracy: 0.3742\n","Epoch 141/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9997\n","Epoch 00141: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 5.7694 - val_accuracy: 0.3746\n","Epoch 142/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9997\n","Epoch 00142: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 5.7510 - val_accuracy: 0.3742\n","Epoch 143/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9997\n","Epoch 00143: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 5.7516 - val_accuracy: 0.3744\n","Epoch 144/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9998\n","Epoch 00144: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 5.7439 - val_accuracy: 0.3726\n","Epoch 145/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9998\n","Epoch 00145: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 5.7480 - val_accuracy: 0.3710\n","Epoch 146/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997\n","Epoch 00146: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 5.7741 - val_accuracy: 0.3740\n","Epoch 147/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998\n","Epoch 00147: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 5.7929 - val_accuracy: 0.3740\n","Epoch 148/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9997\n","Epoch 00148: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 5.8171 - val_accuracy: 0.3732\n","Epoch 149/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9997\n","Epoch 00149: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 5.7620 - val_accuracy: 0.3774\n","Epoch 150/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9998\n","Epoch 00150: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 5.9047 - val_accuracy: 0.3708\n","Epoch 151/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9997\n","Epoch 00151: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 5.7988 - val_accuracy: 0.3764\n","Epoch 152/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9998\n","Epoch 00152: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 5.7735 - val_accuracy: 0.3760\n","Epoch 153/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9998\n","Epoch 00153: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 5ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 5.7984 - val_accuracy: 0.3762\n","Epoch 154/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n","Epoch 00154: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 5.7854 - val_accuracy: 0.3758\n","Epoch 155/200\n","1401/1407 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998\n","Epoch 00155: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 5.7887 - val_accuracy: 0.3718\n","Epoch 156/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9998\n","Epoch 00156: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 5.8167 - val_accuracy: 0.3768\n","Epoch 157/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9997\n","Epoch 00157: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 5.8018 - val_accuracy: 0.3716\n","Epoch 158/200\n","1399/1407 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9997\n","Epoch 00158: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 5.8084 - val_accuracy: 0.3764\n","Epoch 159/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9998\n","Epoch 00159: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 5.8044 - val_accuracy: 0.3764\n","Epoch 160/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9998\n","Epoch 00160: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 5.8014 - val_accuracy: 0.3736\n","Epoch 161/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9998\n","Epoch 00161: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 5.8166 - val_accuracy: 0.3728\n","Epoch 162/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9997\n","Epoch 00162: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 7s 5ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 5.8649 - val_accuracy: 0.3716\n","Epoch 163/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998\n","Epoch 00163: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 7s 5ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 5.8242 - val_accuracy: 0.3740\n","Epoch 164/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9998\n","Epoch 00164: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 5.8243 - val_accuracy: 0.3754\n","Epoch 165/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998\n","Epoch 00165: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 5.8362 - val_accuracy: 0.3742\n","Epoch 166/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998\n","Epoch 00166: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 5.8308 - val_accuracy: 0.3724\n","Epoch 167/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998\n","Epoch 00167: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 5.8595 - val_accuracy: 0.3714\n","Epoch 168/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9998\n","Epoch 00168: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 5.8682 - val_accuracy: 0.3754\n","Epoch 169/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9997\n","Epoch 00169: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 5.8461 - val_accuracy: 0.3726\n","Epoch 170/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9998\n","Epoch 00170: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 5.8616 - val_accuracy: 0.3690\n","Epoch 171/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998\n","Epoch 00171: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 5.9314 - val_accuracy: 0.3708\n","Epoch 172/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n","Epoch 00172: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 5.8913 - val_accuracy: 0.3756\n","Epoch 173/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9997\n","Epoch 00173: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 5.8803 - val_accuracy: 0.3754\n","Epoch 174/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9997\n","Epoch 00174: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 5.8928 - val_accuracy: 0.3766\n","Epoch 175/200\n","1407/1407 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9997\n","Epoch 00175: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 5.8552 - val_accuracy: 0.3726\n","Epoch 176/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9998\n","Epoch 00176: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 5.8776 - val_accuracy: 0.3738\n","Epoch 177/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9998\n","Epoch 00177: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 5.9138 - val_accuracy: 0.3706\n","Epoch 178/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998\n","Epoch 00178: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 5.8767 - val_accuracy: 0.3744\n","Epoch 179/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9998\n","Epoch 00179: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 5.9337 - val_accuracy: 0.3698\n","Epoch 180/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9997\n","Epoch 00180: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 5.8840 - val_accuracy: 0.3768\n","Epoch 181/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n","Epoch 00181: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 5.8938 - val_accuracy: 0.3762\n","Epoch 182/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9998\n","Epoch 00182: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 5.9034 - val_accuracy: 0.3744\n","Epoch 183/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9998\n","Epoch 00183: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 5.9775 - val_accuracy: 0.3738\n","Epoch 184/200\n","1398/1407 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n","Epoch 00184: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 5.9156 - val_accuracy: 0.3750\n","Epoch 185/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9998\n","Epoch 00185: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 5.8952 - val_accuracy: 0.3722\n","Epoch 186/200\n","1396/1407 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998\n","Epoch 00186: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 5.9136 - val_accuracy: 0.3756\n","Epoch 187/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998\n","Epoch 00187: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 5.9050 - val_accuracy: 0.3734\n","Epoch 188/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n","Epoch 00188: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 5.9251 - val_accuracy: 0.3754\n","Epoch 189/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9998\n","Epoch 00189: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 5.9287 - val_accuracy: 0.3736\n","Epoch 190/200\n","1403/1407 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n","Epoch 00190: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 5.9413 - val_accuracy: 0.3728\n","Epoch 191/200\n","1395/1407 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9998\n","Epoch 00191: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 6.0285 - val_accuracy: 0.3744\n","Epoch 192/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9998\n","Epoch 00192: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 5.9337 - val_accuracy: 0.3756\n","Epoch 193/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9998\n","Epoch 00193: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 5.9424 - val_accuracy: 0.3740\n","Epoch 194/200\n","1394/1407 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9998\n","Epoch 00194: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 5.9531 - val_accuracy: 0.3712\n","Epoch 195/200\n","1402/1407 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9998\n","Epoch 00195: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 5.9415 - val_accuracy: 0.3748\n","Epoch 196/200\n","1405/1407 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n","Epoch 00196: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 5.9410 - val_accuracy: 0.3734\n","Epoch 197/200\n","1404/1407 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9998\n","Epoch 00197: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 5.9503 - val_accuracy: 0.3758\n","Epoch 198/200\n","1397/1407 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9997\n","Epoch 00198: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 5.9487 - val_accuracy: 0.3746\n","Epoch 199/200\n","1406/1407 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998\n","Epoch 00199: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 5.9712 - val_accuracy: 0.3734\n","Epoch 200/200\n","1400/1407 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9998\n","Epoch 00200: val_accuracy did not improve from 0.37880\n","1407/1407 [==============================] - 6s 4ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 9.3282 - val_accuracy: 0.2326\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QW-8Utlsxy3J","executionInfo":{"status":"ok","timestamp":1602540731030,"user_tz":240,"elapsed":1276774,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["model.load_weights('/content/gdrive/My Drive/Weights/ResNet18_SGD_BatchNormalization.h5')"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"1X1v6FWH3lrx","executionInfo":{"status":"ok","timestamp":1602540731582,"user_tz":240,"elapsed":1277325,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["y_pred  = model.predict(test_X)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1MpMJx4Peo5","executionInfo":{"status":"ok","timestamp":1602540731582,"user_tz":240,"elapsed":1277323,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["y_pred = y_pred.argmax(-1)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"7GMeoBisPhKX","executionInfo":{"status":"ok","timestamp":1602540731583,"user_tz":240,"elapsed":1277323,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["y_true = test_Y.argmax(-1)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"zbJ9LAu-Pj4M","executionInfo":{"status":"ok","timestamp":1602540732164,"user_tz":240,"elapsed":1277902,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"q96JSzMbPojt","executionInfo":{"status":"ok","timestamp":1602540732166,"user_tz":240,"elapsed":1277903,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["def get_all_metrics(y_pred, y_true):\n","  precision = precision_score(y_true,y_pred, average = 'weighted')\n","  recall = recall_score(y_true , y_pred, average= 'weighted')\n","  accuracy = accuracy_score(y_true, y_pred)\n","  return precision, recall, accuracy"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWjU2XxkPrtC","executionInfo":{"status":"ok","timestamp":1602540732167,"user_tz":240,"elapsed":1277903,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["prec, recall, accuracy = get_all_metrics(y_pred, y_true)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMFMiDYpPvX5","executionInfo":{"status":"ok","timestamp":1602540732167,"user_tz":240,"elapsed":1277897,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}},"outputId":"0a68919a-5427-4580-be20-89abc8d4e53c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('Precision:', prec)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Precision: 0.3852501148825267\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AMQSV7v2Pxa1","executionInfo":{"status":"ok","timestamp":1602540732168,"user_tz":240,"elapsed":1277890,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}},"outputId":"432fc97d-6236-46e0-dbd8-32e1ef09aa19","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('Recall', recall)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Recall 0.3854\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K98F4sp-8ga0","executionInfo":{"status":"ok","timestamp":1602540732168,"user_tz":240,"elapsed":1277884,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}},"outputId":"20b860ce-cdc3-4ab3-92b5-0741cc9528df","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('Accuracy', accuracy)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Accuracy 0.3854\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yw_98lX6P-T1","executionInfo":{"status":"ok","timestamp":1602540732169,"user_tz":240,"elapsed":1277883,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}}},"source":["import matplotlib.pyplot as plt"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0qu9n8Sy1fF","executionInfo":{"status":"ok","timestamp":1602540732169,"user_tz":240,"elapsed":1277881,"user":{"displayName":"Rabiraj Banerjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBMYPLSvlqPpw5Obnc43d3rFlQz1Fhf_RPvmp3DQ=s64","userId":"08202157458524669266"}},"outputId":"657570ef-acfa-4708-a707-e31ef8e87698","colab":{"base_uri":"https://localhost:8080/","height":0}},"source":["history_dict = history.history\n","print(history_dict.keys())\n","loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","\n","epochs = range(1, len(history_dict['accuracy']) + 1)\n","\n","plt.plot(epochs, loss_values, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}